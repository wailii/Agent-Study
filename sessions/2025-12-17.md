# 学习笔记 - 2025-12-17

## 📌 Core Topic

ReAct 模式入门 & 基于 RAG 的需求文档助手架构

## 💡 My Takeaway

- 理解了 ReAct = Reason + Act 的核心循环: Thought → Action → Observation, 本质是给模型一个“边查边想”的 while 循环
- 历史记录 (history) 不是日志装饰, 而是让每一步能够复用之前的尝试, 避免每轮从零开始踩坑
- ReAct 适合作为复杂/不确定任务的高开销模式, 简单问答应该通过意图识别路由到单轮回答以节省 token 和时延
- Planner 更适合任务结构清晰的一次性流程 (先规划后执行), Reflection/Critic 适合在给用户前做“验货”, 删掉没有证据支撑的结论
- 一个规范的 Agent 系统应该围绕统一的 state 读写, Router / ReAct / Critic 都是 State Graph 上的节点
- 用需求文档助手作为落地场景: 通过工具层搜索 PRD/Jira 等, 用 ReAct 做多步分析, 再由验证器检查是否真正回答需求问题且有文档证据

## ❓ Knowledge Gap

- [GAP] 还没有动手在具体框架 (例如 LangGraph) 中建模 State Graph/节点, 不清楚各节点在真实代码中的接口形式
- [GAP] 对工具层与业务系统 (如需求平台/Jira) 集成时的权限、超时和错误重试策略还停留在概念层

## 💻 Code Snippet

```python
# 极简 ReAct 循环伪代码 (围绕 state 读写)
state = {"question": q, "history": [], "step": 0}
MAX_STEPS = 5

while state["step"] < MAX_STEPS:
    thought, action = policy_llm(state)
    obs = run_tool_with_cache(action)
    state["history"].append({"thought": thought, "action": action, "observation": obs})
    state["step"] += 1
    if is_enough_to_answer(state):
        break

draft_answer = answer_llm(state)
final_answer = critic_llm(question=q, draft=draft_answer, evidence=state["history"])
```

## 🔗 Reference

- RULES.md - 学习角色与教学协议
- progress/study-tracker.md - 知识体系清单与总体进度
- sessions/2025-12-16.md - 项目初始化阶段学习记录
